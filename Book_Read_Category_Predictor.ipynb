{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aVbIeP6eGrcE"},"outputs":[],"source":["import gzip\n","from collections import defaultdict\n","import math\n","import scipy.optimize\n","from sklearn import svm\n","import numpy\n","import string\n","import random\n","import string\n","from sklearn import linear_model\n","from operator import itemgetter\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.ensemble import RandomForestClassifier\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","import re\n","# from xgboost import XGBClassifier\n","\n","def readGz(path):\n","  for l in gzip.open(path, 'rt'):\n","    yield eval(l)\n","\n","def readCSV(path):\n","  f = gzip.open(path, 'rt')\n","  f.readline()\n","  for l in f:\n","    yield l.strip().split(',')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DV_F_vq1fvGp"},"outputs":[],"source":["################## 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZMeVUZxE3Il"},"outputs":[],"source":["def accuracy(predictions, y):\n","  correct = 0\n","\n","  # print(predictions[1] == y[1])\n","\n","  for i in range(len(y)):\n","    if predictions[i] == y[i]:\n","      correct += 1\n","\n","  # print(len(y))\n","  return correct / len(predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GC5oTkh8Tjg3"},"outputs":[],"source":["def Jaccard(s1, s2):\n","    s1 = set(s1)\n","    s2 = set(s2)\n","    numer = len(s1.intersection(s2))\n","    denom = len(s1.union(s2))\n","    if denom == 0:\n","        return 0\n","    return numer / denom"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lZeqXyzTGyBs"},"outputs":[],"source":["### Would-read baseline: just rank which books are popular and which are not, and return '1' if a book is among the top-ranked\n","ratingsValid = []\n","ratingsPerItem = defaultdict(list)\n","ratingsPerUser = defaultdict(list)\n","\n","bookCount = defaultdict(int)\n","totalRead = 0\n","\n","for user,book,_ in readCSV(\"train_Interactions.csv.gz\"):\n","  ratingsPerUser[user].append(book)\n","  ratingsPerItem[book].append(user)\n","  ratingsValid.append((user,book))\n","  bookCount[book] += 1\n","  totalRead += 1\n","\n","mostPopular = [(bookCount[x], x) for x in bookCount]\n","mostPopular.sort()\n","mostPopular.reverse()\n","\n","return1 = set()\n","count = 0\n","for ic, i in mostPopular:\n","  count += ic\n","  return1.add(i)\n","  if count > 1.5 * totalRead/2: break\n","  # if count > totalRead/1.5: break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2cSIMW8PhznP"},"outputs":[],"source":["def predict(u,b):\n","  maxSim = 0\n","  users = set(ratingsPerItem[b])\n","  for b2 in ratingsPerUser[u]:\n","      sim = Jaccard(users,set(ratingsPerItem[b2]))\n","      if sim > maxSim:\n","          maxSim = sim\n","  if maxSim > 0.035 or len(ratingsPerItem[b]) > 29:\n","      pred = 1\n","  else:\n","    pred = 0\n","  return pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8a9SmQm5yxSS"},"outputs":[],"source":["predictions = open(\"predictions_Read.csv\", 'w')\n","for l in open(\"pairs_Read.csv\"):\n","  if l.startswith(\"userID\"):\n","    #header\n","    predictions.write(l)\n","    continue\n","  u,b = l.strip().split(',')\n","  pred = predict(u,b)\n","  predictions.write(u + ',' + b + \",\" + str(pred) + \"\\n\")\n","  # if b in return1 and pred == 1:\n","  #   predictions.write(u + ',' + b + \",1\\n\")\n","  # else:\n","  #   predictions.write(u + ',' + b + \",0\\n\")\n","predictions.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xU6SRCX_frT4"},"outputs":[],"source":["###################### 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0H1mcw7HgE8u"},"outputs":[],"source":["data = []\n","\n","for d in readGz(\"train_Category.json.gz\"):\n","    data.append(d)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":332,"status":"ok","timestamp":1668485630309,"user":{"displayName":"Leo Zhang","userId":"01722520536863025981"},"user_tz":480},"id":"n4_418LXvvE3","outputId":"1fddc0fb-c8c7-4aa8-8838-39a6a0a08e31"},"outputs":[{"data":{"text/plain":["{'user_id': 'u75242413',\n"," 'review_id': 'r45843137',\n"," 'rating': 4,\n"," 'review_text': \"a clever book with a deeply troubling premise and an intriguing protagonist. Thompson's clean, sparse prose style kept each page feeling light even as some rather heavy existential questions dropped upon them. I enjoyed it. \\n and that cover design is boom-pow gorgeous.\",\n"," 'n_votes': 1,\n"," 'genre': 'mystery_thriller_crime',\n"," 'genreID': 3}"]},"execution_count":282,"metadata":{},"output_type":"execute_result"}],"source":["data[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DRHHCrnlfrbo"},"outputs":[],"source":["counts = []\n","wordCount = defaultdict(int)\n","punctuation = set(string.punctuation)\n","for d in data:\n","    r = ''.join([c for c in d['review_text'].lower() if not c in punctuation])\n","    for w in r.split():\n","        wordCount[w] += 1\n","\n","counts = [(wordCount[w], w) for w in wordCount]\n","counts.sort()\n","counts.reverse()\n","words = [x[1] for x in counts[:1000]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qKFD4UKamQUA"},"outputs":[],"source":["wordId = dict(zip(words, range(len(words))))\n","wordSet = set(words)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"icdF6mLJgf7O"},"outputs":[],"source":["def feature(datum):\n","    feat = [0]*len(words)\n","    r = ''.join([c for c in datum['review_text'].lower() if not c in punctuation])\n","    for w in r.split():\n","        if w in words:\n","            feat[wordId[w]] += 1\n","    feat.append(1) # offset\n","    return feat"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1668485642909,"user":{"displayName":"Leo Zhang","userId":"01722520536863025981"},"user_tz":480},"id":"jCvcxMyxM8OJ","outputId":"b3fb15d3-a606-4bcb-dec0-eb09b53fca4b"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["nltk.download('stopwords')\n","useless = nltk.corpus.stopwords.words('english')\n","lemmatizer = WordNetLemmatizer()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":93536,"status":"ok","timestamp":1668485736442,"user":{"displayName":"Leo Zhang","userId":"01722520536863025981"},"user_tz":480},"id":"kdxn5zsVS_CL","outputId":"0064e796-1702-4330-cceb-11c309377b76"},"outputs":[{"name":"stdout","output_type":"stream","text":["(100000, 216104)\n"]}],"source":["reviews = []\n","\n","for i in range(len(data)):\n","    review = re.sub('[^a-zA-Z]', ' ', data[i]['review_text']).lower().split()\n","    review = ' '.join([lemmatizer.lemmatize(r) for r in review if not r in set(useless)])\n","    reviews.append(review)\n","\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(reviews)\n","print(X.shape)\n","y = [d['genreID'] for d in data]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44569,"status":"ok","timestamp":1668485781001,"user":{"displayName":"Leo Zhang","userId":"01722520536863025981"},"user_tz":480},"id":"yiJ4jXqpgr5V","outputId":"8a9e8e98-6f32-4cac-9e14-3644ff737982"},"outputs":[],"source":["mod = linear_model.LogisticRegression(C=0.9)\n","mod.fit(X,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DaaZupoLGzxF"},"outputs":[],"source":["input = []\n","for l in readGz(\"test_Category.json.gz\"):\n","  input.append(l)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a0WCoYaiUIPu"},"outputs":[],"source":["reviews = []\n","\n","for i in range(len(input)):\n","    review = re.sub('[^a-zA-Z]', ' ', input[i]['review_text']).lower().split()\n","    review = ' '.join([lemmatizer.lemmatize(r) for r in review if not r in set(useless)])\n","    reviews.append(review)\n","\n","Xvalid = vectorizer.transform(reviews)\n","pred = mod.predict(Xvalid)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oF_92G5Aoc8n"},"outputs":[],"source":["### Category prediction baseline: Just consider some of the most common words from each category\n","i = 0\n","catDict = {\n","  \"children\": 0,\n","  \"comics_graphic\": 1,\n","  \"fantasy_paranormal\": 2,\n","  \"mystery_thriller_crime\": 3,\n","  \"young_adult\": 4\n","}\n","\n","predictions = open(\"predictions_Category.csv\", 'w')\n","predictions.write(\"userID,reviewID,prediction\\n\")\n","for l in readGz(\"test_Category.json.gz\"):\n","  cat = pred[i]\n","  predictions.write(l['user_id'] + ',' + l['review_id'] + \",\" + str(cat) + \"\\n\")\n","  i += 1\n","predictions.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w46qWuLPX54I"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMEydXrMxuIuwR76gdyPrNN","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
