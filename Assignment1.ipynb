{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMEydXrMxuIuwR76gdyPrNN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aVbIeP6eGrcE"},"outputs":[],"source":["import gzip\n","from collections import defaultdict\n","import math\n","import scipy.optimize\n","from sklearn import svm\n","import numpy\n","import string\n","import random\n","import string\n","from sklearn import linear_model\n","from operator import itemgetter\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.ensemble import RandomForestClassifier\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","import re\n","# from xgboost import XGBClassifier\n","\n","def readGz(path):\n","  for l in gzip.open(path, 'rt'):\n","    yield eval(l)\n","\n","def readCSV(path):\n","  f = gzip.open(path, 'rt')\n","  f.readline()\n","  for l in f:\n","    yield l.strip().split(',')"]},{"cell_type":"code","source":["################## 1"],"metadata":{"id":"DV_F_vq1fvGp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy(predictions, y):\n","  correct = 0\n","\n","  # print(predictions[1] == y[1])\n","\n","  for i in range(len(y)):\n","    if predictions[i] == y[i]:\n","      correct += 1\n","\n","  # print(len(y))\n","  return correct / len(predictions)"],"metadata":{"id":"wZMeVUZxE3Il"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def Jaccard(s1, s2):\n","    s1 = set(s1)\n","    s2 = set(s2)\n","    numer = len(s1.intersection(s2))\n","    denom = len(s1.union(s2))\n","    if denom == 0:\n","        return 0\n","    return numer / denom"],"metadata":{"id":"GC5oTkh8Tjg3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Would-read baseline: just rank which books are popular and which are not, and return '1' if a book is among the top-ranked\n","ratingsValid = []\n","ratingsPerItem = defaultdict(list)\n","ratingsPerUser = defaultdict(list)\n","\n","bookCount = defaultdict(int)\n","totalRead = 0\n","\n","for user,book,_ in readCSV(\"train_Interactions.csv.gz\"):\n","  ratingsPerUser[user].append(book)\n","  ratingsPerItem[book].append(user)\n","  ratingsValid.append((user,book))\n","  bookCount[book] += 1\n","  totalRead += 1\n","\n","mostPopular = [(bookCount[x], x) for x in bookCount]\n","mostPopular.sort()\n","mostPopular.reverse()\n","\n","return1 = set()\n","count = 0\n","for ic, i in mostPopular:\n","  count += ic\n","  return1.add(i)\n","  if count > 1.5 * totalRead/2: break\n","  # if count > totalRead/1.5: break"],"metadata":{"id":"lZeqXyzTGyBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict(u,b):\n","  maxSim = 0\n","  users = set(ratingsPerItem[b])\n","  for b2 in ratingsPerUser[u]:\n","      sim = Jaccard(users,set(ratingsPerItem[b2]))\n","      if sim > maxSim:\n","          maxSim = sim\n","  if maxSim > 0.035 or len(ratingsPerItem[b]) > 29:\n","      pred = 1\n","  else:\n","    pred = 0\n","  return pred"],"metadata":{"id":"2cSIMW8PhznP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = open(\"predictions_Read.csv\", 'w')\n","for l in open(\"pairs_Read.csv\"):\n","  if l.startswith(\"userID\"):\n","    #header\n","    predictions.write(l)\n","    continue\n","  u,b = l.strip().split(',')\n","  pred = predict(u,b)\n","  predictions.write(u + ',' + b + \",\" + str(pred) + \"\\n\")\n","  # if b in return1 and pred == 1:\n","  #   predictions.write(u + ',' + b + \",1\\n\")\n","  # else:\n","  #   predictions.write(u + ',' + b + \",0\\n\")\n","predictions.close()"],"metadata":{"id":"8a9SmQm5yxSS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###################### 2"],"metadata":{"id":"xU6SRCX_frT4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = []\n","\n","for d in readGz(\"train_Category.json.gz\"):\n","    data.append(d)"],"metadata":{"id":"0H1mcw7HgE8u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n4_418LXvvE3","executionInfo":{"status":"ok","timestamp":1668485630309,"user_tz":480,"elapsed":332,"user":{"displayName":"Leo Zhang","userId":"01722520536863025981"}},"outputId":"1fddc0fb-c8c7-4aa8-8838-39a6a0a08e31"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'user_id': 'u75242413',\n"," 'review_id': 'r45843137',\n"," 'rating': 4,\n"," 'review_text': \"a clever book with a deeply troubling premise and an intriguing protagonist. Thompson's clean, sparse prose style kept each page feeling light even as some rather heavy existential questions dropped upon them. I enjoyed it. \\n and that cover design is boom-pow gorgeous.\",\n"," 'n_votes': 1,\n"," 'genre': 'mystery_thriller_crime',\n"," 'genreID': 3}"]},"metadata":{},"execution_count":282}]},{"cell_type":"code","source":["counts = []\n","wordCount = defaultdict(int)\n","punctuation = set(string.punctuation)\n","for d in data:\n","    r = ''.join([c for c in d['review_text'].lower() if not c in punctuation])\n","    for w in r.split():\n","        wordCount[w] += 1\n","\n","counts = [(wordCount[w], w) for w in wordCount]\n","counts.sort()\n","counts.reverse()\n","words = [x[1] for x in counts[:1000]]"],"metadata":{"id":"DRHHCrnlfrbo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wordId = dict(zip(words, range(len(words))))\n","wordSet = set(words)"],"metadata":{"id":"qKFD4UKamQUA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def feature(datum):\n","    feat = [0]*len(words)\n","    r = ''.join([c for c in datum['review_text'].lower() if not c in punctuation])\n","    for w in r.split():\n","        if w in words:\n","            feat[wordId[w]] += 1\n","    feat.append(1) # offset\n","    return feat"],"metadata":{"id":"icdF6mLJgf7O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download('stopwords')\n","useless = nltk.corpus.stopwords.words('english')\n","lemmatizer = WordNetLemmatizer()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jCvcxMyxM8OJ","executionInfo":{"status":"ok","timestamp":1668485642909,"user_tz":480,"elapsed":5,"user":{"displayName":"Leo Zhang","userId":"01722520536863025981"}},"outputId":"b3fb15d3-a606-4bcb-dec0-eb09b53fca4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":["reviews = []\n","\n","for i in range(len(data)):\n","    review = re.sub('[^a-zA-Z]', ' ', data[i]['review_text']).lower().split()\n","    review = ' '.join([lemmatizer.lemmatize(r) for r in review if not r in set(useless)])\n","    reviews.append(review)\n","\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(reviews)\n","print(X.shape)\n","y = [d['genreID'] for d in data]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kdxn5zsVS_CL","executionInfo":{"status":"ok","timestamp":1668485736442,"user_tz":480,"elapsed":93536,"user":{"displayName":"Leo Zhang","userId":"01722520536863025981"}},"outputId":"0064e796-1702-4330-cceb-11c309377b76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(100000, 216104)\n"]}]},{"cell_type":"code","source":["mod = linear_model.LogisticRegression(C=0.9)\n","mod.fit(X,y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yiJ4jXqpgr5V","executionInfo":{"status":"ok","timestamp":1668485781001,"user_tz":480,"elapsed":44569,"user":{"displayName":"Leo Zhang","userId":"01722520536863025981"}},"outputId":"8a9e8e98-6f32-4cac-9e14-3644ff737982"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=0.9)"]},"metadata":{},"execution_count":288}]},{"cell_type":"code","source":["input = []\n","for l in readGz(\"test_Category.json.gz\"):\n","  input.append(l)"],"metadata":{"id":"DaaZupoLGzxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reviews = []\n","\n","for i in range(len(input)):\n","    review = re.sub('[^a-zA-Z]', ' ', input[i]['review_text']).lower().split()\n","    review = ' '.join([lemmatizer.lemmatize(r) for r in review if not r in set(useless)])\n","    reviews.append(review)\n","\n","Xvalid = vectorizer.transform(reviews)\n","pred = mod.predict(Xvalid)"],"metadata":{"id":"a0WCoYaiUIPu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Category prediction baseline: Just consider some of the most common words from each category\n","i = 0\n","catDict = {\n","  \"children\": 0,\n","  \"comics_graphic\": 1,\n","  \"fantasy_paranormal\": 2,\n","  \"mystery_thriller_crime\": 3,\n","  \"young_adult\": 4\n","}\n","\n","predictions = open(\"predictions_Category.csv\", 'w')\n","predictions.write(\"userID,reviewID,prediction\\n\")\n","for l in readGz(\"test_Category.json.gz\"):\n","  cat = pred[i]\n","  predictions.write(l['user_id'] + ',' + l['review_id'] + \",\" + str(cat) + \"\\n\")\n","  i += 1\n","predictions.close()"],"metadata":{"id":"oF_92G5Aoc8n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"w46qWuLPX54I"},"execution_count":null,"outputs":[]}]}